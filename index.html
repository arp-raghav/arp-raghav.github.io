<!DOCTYPE HTML>

<html>
	<head>
		<title>Arpit Raghav's Portfolio website'</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<span class="icon fa-gem"></span>
						</div>
						<div class="content">
							<div class="inner">

								<p>Hello, welcome to my portfolio website. My name is </p>
								<h1>Arpit Raghav</h1>
								<p>Please navigate through the sections to know me .</p>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#intro">About Me</a></li>
								<li><a href="#Experience">Experience</a></li>
								<li><a href="#project">Project's</a></li>
								<li><a href="#skills">Skillset</a></li>
								<li><a href="#Contact">Contact Me</a></li>
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
						<article id="intro">
							<h2 class="major">Introduction</h2>
							<span class="image main"><img src="images\ArpitRaghav.jpg" alt="" /></span>
							<p>Hello there! I'm Arpit Raghav, a dedicated and accomplished Data Analyst based in Liverpool. With an experience of 3+ years in data-oriented roles, I am passionate about extracting valuable insights from complex datasets and translating them into actionable business strategies. My academic journey has been marked by excellence, with a Bachelor's degree focused on Computer Science and a Master's degree in Big Data and High-Performance Computing from the prestigious University of Liverpool. My extensive skill set includes expertise in Advance Python, Power BI, MS 365 Suite, Azure cloud computing, as well as creating and maintaining robust Machine Learning models. Additionally, I possess hands-on experience working with various data sources, ranging from SQL servers, Azure, Postgres, SharePoint to Microsoft Fabric. <br><br> Please explore the experience section to know some of the work I have done and the technologies I have hands on experience and excel at. <br> If you have some more time on your hands , I would highly recommend you to see some of my projects I have done either in my academic time or personal time, for most of them code can be found on my github repository, link in the contact section.. <br> Thanks again</p>
						</article>

						<!-- Work -->
						<article id="Experience">
							<h2 class="major">Experience</h2>
							<span class="image main"><img src="images\exp.jpeg" alt="" /></span>
							<P><strong>University of Liverpool - Data & Analytics Manager (Apr 2024 - Present)</strong><br>Working in University of Liverpool, I will be working alongside my compact team of Data Analysts. As part of my role I am responsible for automation of various process and reporting cadences, integration of cloud servises to our working portfolio and implementing and utilising large scale analysis and predictive models. </P>
                                                    	<P><strong>D2-Global - Data Analyst (Oct 2022 - Apr 2024)</strong><br>As a dedicated Data & Reporting Analyst at D2-Global in Manchester, United Kingdom, I am proud to be an integral part of the TRU West Alliance team, collaborating with industry giants BAM and Network Rail on the monumental TransPennine route upgrade project. This multi-billion-pound investment is a game-changer for North England's connectivity, and I play a crucial role in driving informed decision-making through data.<br>My responsibilities encompass leading the end-to-end development of diverse Power BI dashboards, from stakeholder requirements gathering to deployment and maintenance. I've meticulously designed data architectures, leveraging the full capacity of the MS suite and automating processes through Power Automate, OneLake datahub, and Azure suite services. The integration of data pipelines over Azure, MS Fabric, and SharePoint ensures a reliable flow of data to the Power BI dashboards, providing key stakeholders with valuable insights into the TRU project's progress and performance. <br>  In addition to creating and maintaining databases using MySQL for optimal data integrity, I've implemented ETL pipelines using Talend/Informatica over Azure and utilized Apache Airflow for seamless data extraction, transformation, and loading processes. These accomplishments have not only earned me the prestigious title of Employee of the Period at TRU but also a nomination as a finalist for the world's biggest Project Controls Expo in 2023 in London.  <br>  I take pride in contributing to the TRU project's success by developing 17 high-quality Power BI dashboards that meet stakeholder requirements and offer critical insights for strategic decision-making. My commitment to excellence in data analytics is evident in the positive impact on project outcomes, empowering stakeholders with the tools they need for a transformative journey in railway infrastructure. </P>
							<p><strong>Beyond MI Ltd - Financial Crime Data Analyst (June 2022 - Sep 2022)</strong>In a significant role at Beyond MI Ltd in London, I served as a Financial Crime Data Analyst. Here, I played a pivotal role in building a robust Machine Learning model utilizing binary classification techniques like Decision Trees, K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Naive Bayes. The primary objective of this model was to identify outliers and detect fraudulent transactions effectively. Furthermore, I delved into predictive modeling, leveraging Long Short-Term Memory (LSTM) and linear regression techniques to forecast future fraudulent transactions and uncover the underlying causes behind such occurrences.</p>
							<p><strong>University of Liverpool - Teaching Assistant (Sep 2021 - Jan 2022)</strong>During my academic journey at the University of Liverpool, I had the privilege of serving as a Teaching Assistant for two critical subjects: Advanced SQL and Design Systems. In this capacity, I facilitated tutorials and conducted engaging lab sessions for both first and second-year students, guiding them through advanced SQL concepts and honing their skills in project design and management. This rewarding experience allowed me to share my knowledge, support fellow students, and foster an environment of collaborative learning.</p>
							<p><strong>Deloitte Consulting - Analyst (Jul 2020 - Aug 2021)</strong>My professional journey also led me to Deloitte Consulting, where I worked as an Associate Analyst in the AdTech domain. Collaborating with Verizon Media, I focused on identifying scam trends, including fake websites, frauds, and country-wide anti-compliance ads. To accomplish this, I skillfully utilized SQL Server and Falcon databases, and incorporated cutting-edge technologies such as Google Analytics, Google AdSense, and Python to extract meaningful insights and ensure comprehensive fraud detection.</p>
							<br> <br>
							<p>In each of these diverse experiences, I have continuously pushed boundaries and applied my expertise to drive significant contributions. My passion for data analysis and visualization, combined with my diverse skill set, enables me to thrive in dynamic and complex projects, delivering impactful outcomes. <br> <br> Let's harness the power of data together!</p>
						</article>

						<!-- About -->
						<article id="project">
							<h2 class="major">Academic and personal project's</h2>
							<span class="image main"><img src="images\proj.jpeg" alt="" /></span>
							<ul>
								<li>Binary Class Perceptron allgorithm implementation on Iris Dataset using python</li>
								<li>K Means Clustering algorithm on multiple datasets using python</li>
								<li>Implemented Reinforcement learning while comparing a greedy vs 2 e greedy method on 10 armed testband using python</li>
								<li>Implemented Reinforcement learning for Comparing SARSA and Q-Learning in the cliff walking learning model using python</li>
								<li>Literature review on Algorithamic Bias in AI and ML</li>
								<li>Extracting symptoms and Diagnosis information from synthetic medical abstracts for Automatic Diagnosis Prediction using NLP(Currently Doing)</li>
								<li>Secure File Transfer Network in a local heathcare network using Blockchain(Bachelor's Major Proeject)</li>
								<li>Data Visualization and insights for a local foodchain</li>
								<li>Visual Dashboard of the covid effect over time using Tableau</li>
								<li>Social Network Analysis using Python</li>
								<li>Performed data cleaning operations and implemented PCA analysis for a Fortune 500 Stock open/close dataset using Python</li>
								<li> Advanced Power BI Dashboards (Commercial, KPI, Change, Risk, Schedule Time series etc </li>

							</ul>
						</article>
						<article id="skills">
							<h2 class="major">Skill's</h2>
							<span class="image main"><img src="images\skill.jpeg" alt="" /></span>
							<ul>
								<li>
									Programming Languages
									<ul>
										<li><strong>Python</strong>- Spacy, Pandas, Sckit Leanr, Keras and more</li>
										<li>Scala</li>
										<li>Advanced SQL<li>
										<li>M COde<li>
										<li>JavaScript</li>
										<li>R</li>
										


									</ul>
								</li>
								<li>
									Data Visualisation Tools
									<ul>
										<li><strong>Adavanced Power BI (Advanced DAX , M , Power Query, Dynamic Measures , PBI Service functionality with Fabric and Azure Integration</strong></li>
										<li>Tableau</li>
										<li>Business Objects</li>
										<li>Google Data Studio</li>
										<li>Advanced Excel</li>
										<li>MATLAB</li>
									</ul>
								</li>

								<li>
									Big Data Tools, Cloud, ETL & General
									<ul>
										
										<li>Azure</li>
										<li>Salesfoce Data Cloud</li>
										<li><strong>Microsoft FABRIC </strong> consisting Onelake , Data Marts , Data Warehouse, Semantic Data Models </li>
										<li>Hadoop (HDFS)</li>
										<li>Spark - General , Spark , Airflow</li>
										<li>Jira</li>
										<li>MS Office (outlook,access,excel etc)</li>
										<li>SQL</li>
										<li>Luigi</li>
										<li>Barkla (UOL HPC resource)</li>
										<li>MATLAB</li>

									</ul>
								</li>


							</ul>
						</article>

						<!-- Contact -->
						<article id="Contact">
							<h2 class="major">Contact</h2>
							<span class="image main"><img src="images\cont.jpeg" alt="" /></span>
							<p>Email      - arpitraghav13@gmail.com</p>
							<p>Phone      - +44(0)7824061065</p>
							<p>Linkedin   - <a href="https://www.linkedin.com/in/arpit-raghav-a45907190/">Arpit Raghav</a></p>
							<p>GitHub      - <a href="https://github.com/arp-raghav">arp-raghav</a></p>
						</article>

		

	</body>
</html>
